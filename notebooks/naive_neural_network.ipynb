{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKBPbWwiV5BCcVXpdS/LMr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kailashSwaminathan/cce_dl4ai_2023/blob/%E0%A4%B8%E0%A4%BE%E0%A4%97%E0%A4%B0%E0%A4%82/notebooks/naive_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **A NAIVE IMPLEMENTATION OF NEURAL NETWORK USING TENSORFLOW**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YgbPI8ItE7pk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdQGdVKgB_3y"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras import Input\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.utils import plot_model\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of a Dense Layer class"
      ],
      "metadata": {
        "id": "q1i6ycA7Fg1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveDenseLayer:\n",
        "    def __init__(self, input_size, output_size, activation): \n",
        "        self.activation = activation\n",
        "        w_shape = (input_size, output_size)\n",
        "        w_initial = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
        "        # For updation the type should be tf.Variable\n",
        "        self.weights = tf.Variable(w_initial)\n",
        "        b_shape = (output_size,)\n",
        "        b_initial = tf.zeros(b_shape)\n",
        "        self.biases = tf.Variable(b_initial)\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        # self.biases is broadcasted\n",
        "        return self.activation(tf.matmul(inputs, self.weights) + self.biases) \n",
        "\n",
        "   @property\n",
        "   def weights(self):\n",
        "       return (self.weights, self.biases)"
      ],
      "metadata": {
        "id": "y-H3WZkVFpYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveSequential:\n",
        "\n",
        "    def __init__(self, layers):\n",
        "        \"\"\" layers: list\n",
        "        \"\"\"\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "        weights = []\n",
        "        for layer in self.layers:\n",
        "            weights += layer.weights\n",
        "        return weights\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "ziMBPTXIWpEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NaiveSequential([\n",
        "    NaiveDenseLayer(input_size=28*28, output_size=512, activation=tf.nn.relu),\n",
        "    NaiveDenseLayer(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
        "])"
      ],
      "metadata": {
        "id": "y5ZHTwMaYDOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "O-Fwr2WTYmUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape((len(train_images), 28*28)).astype(\"float32\")/255\n",
        "test_images = test_images.reshape((len(test_images), 28*28)).astype(\"float32\")/255"
      ],
      "metadata": {
        "id": "DNHKJiBQnF1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchGenerator:\n",
        "\n",
        "    def __init__(self, images, labels, batch_size=128):\n",
        "        assert len(images) == len(labels)\n",
        "        self.index = 0\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.num_batches = math.ceil(len(images)/batch_size)\n",
        "\n",
        "    def next(self):\n",
        "        images = self.images[self.index : (self.index + self.batch_size)]\n",
        "        labels = self.labels[self.index : (self.index + self.batch_size)]\n",
        "        self.index += self.batch_size\n",
        "        return images, labels\n",
        "\n",
        "    @property\n",
        "    def batch_size()\n",
        "        return self.batch_size"
      ],
      "metadata": {
        "id": "Wb4o_-n8noe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "def update_weights(gradients, weights):\n",
        "    for g,w in zip(gradients, weights):\n",
        "        w.assign_sib(g*learning_rate)  # w -= g*lr\n",
        "\n",
        "\n",
        "def one_training_step(model, images_batch, labels_batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images_batch)\n",
        "        per_sample_losses = keras.losses.sparse_categorical_crossentropy( labels_batch, predictions )\n",
        "        average_loss = tf.reduce_mean(per_sample_losses)\n",
        "    gradients = tape.gradient(average_loss, model.weights)\n",
        "    update_weights(gradients, model.weights)\n",
        "    return average_loss\n",
        "\n",
        "def fit(model, images, labels, epochs, batch_size=128):\n",
        "    for epoch in range(epochs):\n",
        "        batch_generator = BatchGenerator(images, labels)\n",
        "        for batch_count in range(batch_generator.num_batches)"
      ],
      "metadata": {
        "id": "Hmk7cBBmuDKB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}